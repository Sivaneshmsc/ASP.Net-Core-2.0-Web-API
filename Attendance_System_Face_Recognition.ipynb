{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Attendance System - Face Recognition.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sivaneshmsc/ASP.Net-Core-2.0-Web-API/blob/master/Attendance_System_Face_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-tnUT5DVPGN"
      },
      "source": [
        "# **SUBSCRIBE to the [channel](https://www.youtube.com/user/19daredevill?sub_confirmation=1) to learn cool things**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKoo2OPsVT-9"
      },
      "source": [
        "![Subscribe](https://media3.giphy.com/media/XGILFirobxDWglaUyj/giphy.gif?cid=ecf05e474afdd7ef5fe2c0fa50f87822d705fbb2613a3b5c&rid=giphy.gif)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgOKBYOHVG2D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db57b974-de4c-4684-dd7f-382f5040f163"
      },
      "source": [
        "!git clone https://github.com/misbah4064/face_recognition.git\n",
        "%cd face_recognition"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'face_recognition'...\n",
            "remote: Enumerating objects: 26, done.\u001b[K\n",
            "remote: Counting objects: 100% (26/26), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 26 (delta 5), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (26/26), done.\n",
            "/content/face_recognition\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlJVHpPytrLc",
        "outputId": "3e583af4-0984-48a0-a126-dac52b41d054",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install playsound"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting playsound\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/16/10d897b0a83fb4b05b03a63d7a2667ab75f857f67f7062fd447dd3f49bf7/playsound-1.2.2-py2.py3-none-any.whl\n",
            "Installing collected packages: playsound\n",
            "Successfully installed playsound-1.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pshDkWdyVYvy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c847c6c0-4256-418a-9475-ac82d922d1a1"
      },
      "source": [
        "!pip install face_recognition"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting face_recognition\n",
            "  Downloading https://files.pythonhosted.org/packages/1e/95/f6c9330f54ab07bfa032bf3715c12455a381083125d8880c43cbe76bb3d0/face_recognition-1.3.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from face_recognition) (1.19.5)\n",
            "Collecting face-recognition-models>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cf/3b/4fd8c534f6c0d1b80ce0973d01331525538045084c73c153ee6df20224cf/face_recognition_models-0.3.0.tar.gz (100.1MB)\n",
            "\u001b[K     |████████████████████████████████| 100.2MB 42kB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.0.0)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (19.18.0)\n",
            "Building wheels for collected packages: face-recognition-models\n",
            "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566173 sha256=a328efc7952b9d3256be0eae6a5f6948ea137c2b05d8c335fdc4aaf9cda533ff\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/99/18/59c6c8f01e39810415c0e63f5bede7d83dfb0ffc039865465f\n",
            "Successfully built face-recognition-models\n",
            "Installing collected packages: face-recognition-models, face-recognition\n",
            "Successfully installed face-recognition-1.3.0 face-recognition-models-0.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rF-BTaHyborv"
      },
      "source": [
        "# **Training Images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjXPiwpeVba3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f109d75-cd9b-45e7-afcc-e3ed26522ed8"
      },
      "source": [
        "import face_recognition\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw\n",
        "from IPython.display import display\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "from datetime import datetime\n",
        "import time\n",
        "from playsound import playsound\n",
        "from google.colab import output\n",
        "\n",
        "face_1 = face_recognition.load_image_file(\"/content/face_recognition/elon.jpg\")\n",
        "face_1_encoding = face_recognition.face_encodings(face_1)[0]\n",
        "\n",
        "face_2 = face_recognition.load_image_file(\"/content/face_recognition/Donald Trump.jpg\")\n",
        "face_2_encoding = face_recognition.face_encodings(face_2)[0]\n",
        "\n",
        "face_3 = face_recognition.load_image_file(\"/content/face_recognition/Sivan.jpg\")\n",
        "face_3_encoding = face_recognition.face_encodings(face_3)[0]\n",
        "\n",
        "face_4 = face_recognition.load_image_file(\"/content/face_recognition/Theju.jpg\")\n",
        "face_4_encoding = face_recognition.face_encodings(face_4)[0]\n",
        "\n",
        "\n",
        "known_face_encodings = [\n",
        "    face_1_encoding,\n",
        "    face_2_encoding,\n",
        "    face_3_encoding,\n",
        "    face_4_encoding\n",
        "]\n",
        "known_face_names = [\n",
        "    \"Elon Musk\",\n",
        "    \"Donald Trump\",\n",
        "    \"Sivan Speed\",\n",
        "    \"Theju\"\n",
        "]\n",
        "print(\"Done learning and creating profiles\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done learning and creating profiles\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1H9QzThobuSw"
      },
      "source": [
        "# **Initializing function to add names to the \"attendance_list.csv\" file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVEbG_BiZC-8"
      },
      "source": [
        "import pytz\n",
        "IST = pytz.timezone('Asia/Kolkata')\n",
        "def makeAttendanceEntry(name):\n",
        "    with open('/content/face_recognition/attendance_list.csv','r+') as FILE:\n",
        "        allLines = FILE.readlines()\n",
        "        attendanceList = []\n",
        "        for line in allLines:\n",
        "            entry = line.split(',')\n",
        "            attendanceList.append(entry[0])\n",
        "        if name not in attendanceList:\n",
        "            now = datetime.now(IST)\n",
        "            dtString = now.strftime('%d/%b/%Y, %H:%M:%S')\n",
        "            FILE.writelines(f'\\n{name},{dtString}')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvNxvs5zb42r"
      },
      "source": [
        "# **Performing Face Recognition and Entering Attendance with time-stamp**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXeY90Z_rSUN"
      },
      "source": [
        "from IPython.display import display, Javascript\r\n",
        "from google.colab.output import eval_js\r\n",
        "from base64 import b64decode\r\n",
        "\r\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\r\n",
        "  js = Javascript('''\r\n",
        "    async function takePhoto(quality) {\r\n",
        "      const div = document.createElement('div');\r\n",
        "      //const capture = document.createElement('button');\r\n",
        "      //capture.textContent = 'Capture';\r\n",
        "      //div.appendChild(capture);\r\n",
        "\r\n",
        "      const video = document.createElement('video');\r\n",
        "      video.style.display = 'block';\r\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\r\n",
        "\r\n",
        "      document.body.appendChild(div);\r\n",
        "      div.appendChild(video);\r\n",
        "      video.srcObject = stream;\r\n",
        "      await video.play();\r\n",
        "\r\n",
        "      // Resize the output to fit the video element.\r\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\r\n",
        "\r\n",
        "      // Wait for Capture to be clicked.\r\n",
        "      //resolve();\r\n",
        "      //await new Promise((resolve) => capture.onclick = resolve);\r\n",
        "\r\n",
        "      const canvas = document.createElement('canvas');\r\n",
        "      canvas.width = video.videoWidth;\r\n",
        "      canvas.height = video.videoHeight;\r\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\r\n",
        "      stream.getVideoTracks()[0].stop();\r\n",
        "      div.remove();\r\n",
        "      return canvas.toDataURL('image/jpeg', quality);\r\n",
        "    }\r\n",
        "    ''')\r\n",
        "  display(js)\r\n",
        "  data = eval_js('takePhoto({})'.format(quality))\r\n",
        "  binary = b64decode(data.split(',')[1])\r\n",
        "  with open(filename, 'wb') as f:\r\n",
        "    f.write(binary)\r\n",
        "  return filename"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4VTNtaUVfwm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fb141773-1381-4da6-cdce-6f81e5dcc9d4"
      },
      "source": [
        "while True:\n",
        "  try:\n",
        "    file_name = take_photo('Faces.jpg')\n",
        "    time.sleep(2)\n",
        "    unknown_image = face_recognition.load_image_file(file_name)\n",
        "    unknown_image_to_draw = cv2.imread(file_name)\n",
        "\n",
        "    face_locations = face_recognition.face_locations(unknown_image)\n",
        "    face_encodings = face_recognition.face_encodings(unknown_image, face_locations)\n",
        "\n",
        "    pil_image = Image.fromarray(unknown_image)\n",
        "    draw = ImageDraw.Draw(pil_image)\n",
        "\n",
        "    for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
        "        output.clear()\n",
        "        # See if the face is a match for the known face(s)\n",
        "        matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
        "\n",
        "        name = \"Unknown\"\n",
        "\n",
        "        face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
        "        best_match_index = np.argmin(face_distances)\n",
        "        if matches[best_match_index]:\n",
        "            name = known_face_names[best_match_index]\n",
        "\n",
        "        # Draw a box around the face using the Pillow module\n",
        "        cv2.rectangle(unknown_image_to_draw,(left, top), (right, bottom), (0,255,0),3 )\n",
        "        draw.rectangle(((left, top), (right, bottom)), outline=(0, 255, 255))\n",
        "        cv2.putText(unknown_image_to_draw,name,(left,top-20), cv2.FONT_HERSHEY_SIMPLEX,1, (0,0,255), 2,cv2.LINE_AA)\n",
        "        print(name)\n",
        "        makeAttendanceEntry(name)\n",
        "\n",
        "        # playsound(\"/content/face_recognition/short_notification.mp3\")\n",
        "\n",
        "    # display(pil_image)\n",
        "    cv2_imshow(unknown_image_to_draw)\n",
        "  except KeyboardInterrupt:\n",
        "    output.clear()\n",
        "    print('Bye bye...')\n",
        "    break\n",
        "    pass\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bye bye...\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}